{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of different MFI algortims to indentify the fastest one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, define constants, base functions and load positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from traceback import print_tb\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy import stats\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit, njit\n",
    "from numba.typed import List\n",
    "from matplotlib import ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_grid=np.array((-np.pi, -np.pi))\n",
    "max_grid=np.array((np.pi, np.pi))\n",
    "nbins=np.array((200, 200))\n",
    "\n",
    "gridx = np.linspace(min_grid[0], max_grid[0], nbins[0])\n",
    "gridy = np.linspace(min_grid[1], max_grid[1], nbins[1])\n",
    "grid_space = np.array(((max_grid[0] - min_grid[0]) / (nbins[0]-1), (max_grid[1] - min_grid[1]) / (nbins[1]-1)))\n",
    "X, Y = np.meshgrid(gridx, gridy)\n",
    "\n",
    "bw = 0.05\n",
    "bw2 = bw**2\n",
    "stride = 10\n",
    "const = (1 / (bw * np.sqrt(2 * np.pi) * stride))\n",
    "kT = 2.49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_HILLS_2D(hills_name=\"../data/HILLS\"):\n",
    "\t\"\"\"Load 2-dimensional hills data (includes time, position_x, position_y, hills_parameters ).\n",
    "\t\n",
    "\tArgs:\n",
    "\t\thills_name (str, optional): Name of hills file. Defaults to \"HILLS\".\n",
    "\tReturns:\n",
    "\t\tnp.array: Array with hills data\n",
    "\t\"\"\"\n",
    "\tfor file in glob.glob(hills_name):\n",
    "\t\thills = np.loadtxt(file)\n",
    "\t\thills = np.concatenate(([hills[0]], hills[:-1]))\n",
    "\t\thills[0][5] = 0\n",
    "\treturn hills\n",
    "\n",
    "def load_position_2D(position_name=\"../data/position\"):\n",
    "\t\"\"\"Load 2-dimensional position/trajectory data.\n",
    "\n",
    "\tArgs:\n",
    "\t\tposition_name (str, optional): Name of position file. Defaults to \"position\".\n",
    "\n",
    "\tReturns:\n",
    "\t\tlist: 2 * np.array with position data of each dimension ([position_x, position_y])\n",
    "\t\"\"\"\n",
    "\tfor file1 in glob.glob(position_name):\n",
    "\t\tcolvar = np.loadtxt(file1)\n",
    "\t\tposition_x = colvar[:-1, 1]\n",
    "\t\tposition_y = colvar[:-1, 2]\n",
    "\treturn [position_x, position_y]\n",
    "\n",
    "def find_periodic_point(x_coord, y_coord, min_grid, max_grid, periodic):\n",
    "    \n",
    "\t\"\"\"Finds periodic copies of input coordinates. \n",
    "\t\n",
    "\tArgs:\n",
    "\t\tx_coord (float): CV1-coordinate\n",
    "\t\ty_coord (float): CV2-coordinate\n",
    "\t\tmin_grid (list): list of CV1-minimum value of grid and CV2-minimum value of grid\n",
    "\t\tmax_grid (list): list of CV1-maximum value of grid and CV2-maximum value of grid\n",
    "\t\tperiodic (binary): information if system is periodic. value of 0 corresponds to non-periodic system; function will only return input coordinates. Value of 1 corresponds to periodic system; function will return input coordinates with periodic copies.\n",
    "\tReturns:\n",
    "\t\tlist: list of [x-coord, y-coord] pairs\n",
    "\t\"\"\"\n",
    "\n",
    "\tcoord_list = []\n",
    "\tcoord_list.append([x_coord, y_coord])\n",
    "\t\n",
    "\tif periodic == 1:\n",
    "\t\t# Use periodic extension for defining PBC\n",
    "\t\tperiodic_extension = periodic * 1 / 2\n",
    "\t\tgrid_ext = (1 / 2) * periodic_extension * (max_grid - min_grid)\n",
    "\n",
    "\t\t# There are potentially 4 points, 1 original and 3 periodic copies, or less.\n",
    "\n",
    "\t\tcopy_record = [0, 0, 0, 0]\n",
    "\t\t# check for x-copy\n",
    "\t\tif x_coord < min_grid[0] + grid_ext[0]:\n",
    "\t\t\tcoord_list.append([x_coord + 2 * np.pi, y_coord])\n",
    "\t\t\tcopy_record[0] = 1\n",
    "\t\telif x_coord > max_grid[0] - grid_ext[0]:\n",
    "\t\t\tcoord_list.append([x_coord - 2 * np.pi, y_coord])\n",
    "\t\t\tcopy_record[1] = 1\n",
    "\t\t# check for y-copy\n",
    "\t\tif y_coord < min_grid[1] + grid_ext[1]:\n",
    "\t\t\tcoord_list.append([x_coord, y_coord + 2 * np.pi])\n",
    "\t\t\tcopy_record[2] = 1\n",
    "\t\telif y_coord > max_grid[1] - grid_ext[1]:\n",
    "\t\t\tcoord_list.append([x_coord, y_coord - 2 * np.pi])\n",
    "\t\t\tcopy_record[3] = 1\n",
    "\t\t# check for xy-copy\n",
    "\t\tif sum(copy_record) == 2:\n",
    "\t\t\tif copy_record[0] == 1 and copy_record[2] == 1:\n",
    "\t\t\t\tcoord_list.append([x_coord + 2 * np.pi, y_coord + 2 * np.pi])\n",
    "\t\t\telif copy_record[1] == 1 and copy_record[2] == 1:\n",
    "\t\t\t\tcoord_list.append([x_coord - 2 * np.pi, y_coord + 2 * np.pi])\n",
    "\t\t\telif copy_record[0] == 1 and copy_record[3] == 1:\n",
    "\t\t\t\tcoord_list.append([x_coord + 2 * np.pi, y_coord - 2 * np.pi])\n",
    "\t\t\telif copy_record[1] == 1 and copy_record[3] == 1:\n",
    "\t\t\t\tcoord_list.append([x_coord - 2 * np.pi, y_coord - 2 * np.pi])        \n",
    "\n",
    "\treturn coord_list\n",
    "\n",
    "def mean_force_variance(Ftot_den, Ftot_den2, Ftot_x, Ftot_y, ofv_num_x, ofv_num_y, Ftot_den_limit=10**-10):\n",
    "\n",
    "\tbessel_corr = np.divide(Ftot_den**2 , (Ftot_den**2-Ftot_den2), out=np.zeros_like(Ftot_den), where=(Ftot_den**2-Ftot_den2) > 0)\n",
    "\t\t\n",
    "\tofv_x = (np.divide(ofv_num_x , Ftot_den, out=np.zeros_like(Ftot_den), where=Ftot_den > Ftot_den_limit) - Ftot_x**2) * bessel_corr\n",
    "\tofe_x = np.sqrt(ofv_x)\n",
    "\t\n",
    "\tofv_y = (np.divide(ofv_num_y , Ftot_den, out=np.zeros_like(Ftot_den), where=Ftot_den > Ftot_den_limit) - Ftot_y**2) * bessel_corr\n",
    "\tofe_y = np.sqrt(ofv_y)\n",
    "\t\n",
    "\tofv = np.sqrt(ofv_x**2 + ofv_y**2)\n",
    "\tofe = np.sqrt(ofe_x**2 + ofe_y**2)\n",
    "\t\t\n",
    "\treturn [ofv, ofe]\n",
    "\n",
    "def FFT_intg_2D(FX, FY, min_grid=np.array((-np.pi, -np.pi)), max_grid=np.array((np.pi, np.pi)), nbins=0):\n",
    "\t\"\"\"2D integration of force gradient (FX, FY) to find FES using Fast Fourier Transform.\n",
    "\n",
    "\tArgs:\n",
    "\t\tFX (array of size (nbins[0], nbins[1])): CV1 component of the Mean Force.\n",
    "\t\tFY (array of size (nbins[0], nbins[1])): CV1 component of the Mean Force.\n",
    "\t\tmin_grid (array, optional): Lower bound of the simulation domain. Defaults to np.array((-np.pi, -np.pi)).\n",
    "\t\tmin_grid (array, optional): Upper bound of the simulation domain. Defaults to np.array((np.pi, np.pi)).\n",
    "\t\tnbins (int, optional): number of bins in CV1,CV2. Defaults to 0. When nbins=0, nbins will take the shape of FX.\n",
    "\n",
    "\tReturns:\n",
    "\t\tX: array of size (nbins[0], nbins[1]) - CV1 grid positions\n",
    "\t\tY: array of size (nbins[0], nbins[1]) - CV2 grid positions\n",
    "\t\tfes: array of size (nbins[0], nbins[1]) - Free Energy Surface\n",
    "\t\"\"\"\n",
    "\tif hasattr(nbins, \"__len__\") == False: nbins = np.shape(FX)        \n",
    "\t\n",
    "\tgridx = np.linspace(min_grid[0], max_grid[0], nbins[0])\n",
    "\tgridy = np.linspace(min_grid[1], max_grid[1], nbins[1])\n",
    "\tgrid_spacex = (max_grid[0] - min_grid[0]) / (nbins[0] - 1)\n",
    "\tgrid_spacey = (max_grid[1] - min_grid[1]) / (nbins[1] - 1)\n",
    "\tX, Y = np.meshgrid(gridx, gridy)\n",
    "\n",
    "\t# Calculate frequency\n",
    "\tfreq_1dx = np.fft.fftfreq(nbins[0], grid_spacex)\n",
    "\tfreq_1dy = np.fft.fftfreq(nbins[1], grid_spacey)\n",
    "\tfreq_x, freq_y = np.meshgrid(freq_1dx, freq_1dy)\n",
    "\tfreq_hypot = np.hypot(freq_x, freq_y)\n",
    "\tfreq_sq = np.where(freq_hypot != 0, freq_hypot ** 2, 1E-10)\n",
    "\t# FFTransform and integration\n",
    "\tfourier_x = (np.fft.fft2(FX) * freq_x) / (2 * np.pi * 1j * freq_sq)\n",
    "\tfourier_y = (np.fft.fft2(FY) * freq_y) / (2 * np.pi * 1j * freq_sq)\n",
    "\t# Reverse FFT\n",
    "\tfes_x = np.real(np.fft.ifft2(fourier_x))\n",
    "\tfes_y = np.real(np.fft.ifft2(fourier_y))\n",
    "\t# Construct whole FES\n",
    "\tfes = fes_x + fes_y\n",
    "\tfes = fes - np.min(fes)\n",
    "\treturn [X, Y, fes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "HILLS = load_HILLS_2D(\"../data/HILLS40\")\n",
    "[p_x,p_y] = load_position_2D(\"../data/position40\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (0) Naive Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of evaluations\n",
    "nhills = 200\n",
    "n_eval = int(nhills / (stride/10))\n",
    "[pos_x, pos_y] = [p_x[:stride*n_eval],p_y[:stride*n_eval]]\n",
    "hills = HILLS[:n_eval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MFI_2D(HILLS=\"HILLS\", position_x=\"position_x\", position_y=\"position_y\", bw=1, kT=1,\n",
    "\t\t   min_grid=np.array((-np.pi, -np.pi)), max_grid=np.array((np.pi, np.pi)), nbins=np.array((200, 200)),\n",
    "\t\t   log_pace=5, error_pace=10, WellTempered=1, nhills=-1, periodic=1):\n",
    "\n",
    "\tfor _init in range(1):\n",
    "\t\tgridx = np.linspace(min_grid[0], max_grid[0], nbins[0])\n",
    "\t\tgridy = np.linspace(min_grid[1], max_grid[1], nbins[1])\n",
    "\t\tgrid_space = np.array(((max_grid[0] - min_grid[0]) / (nbins[0]-1), (max_grid[1] - min_grid[1]) / (nbins[1]-1)))\n",
    "\t\tX, Y = np.meshgrid(gridx, gridy)\n",
    "\t\tstride = int(len(position_x) / len(HILLS))\n",
    "\t\tconst = (1 / (bw * np.sqrt(2 * np.pi) * stride))\n",
    "\n",
    "\t\t# Optional - analyse only nhills, if nhills is set\n",
    "\t\tif nhills > 0:\n",
    "\t\t\ttotal_number_of_hills = nhills\n",
    "\t\telse:\n",
    "\t\t\ttotal_number_of_hills = len(HILLS)\n",
    "\t\tbw2 = bw ** 2\n",
    "\n",
    "\t\t# Initialize force terms\n",
    "\t\tFbias_x = np.zeros(nbins)\n",
    "\t\tFbias_y = np.zeros(nbins)\n",
    "\t\tFtot_num_x = np.zeros(nbins)\n",
    "\t\tFtot_num_y = np.zeros(nbins)\n",
    "\t\tFtot_den = np.zeros(nbins)\n",
    "\t\tFtot_den2 = np.zeros(nbins)\n",
    "\t\tcutoff=np.zeros(nbins)\n",
    "\t\tofv_num_x = np.zeros(nbins)\n",
    "\t\tofv_num_y = np.zeros(nbins)\n",
    "\t\tvolume_history = []\n",
    "\t\tofe_history = []\n",
    "\t\ttime_history = []\n",
    "\n",
    "\t\t#Don't Calculate static force in this case\n",
    "\t\tF_static_x = np.zeros(nbins)\n",
    "\t\tF_static_y = np.zeros(nbins)\n",
    "\n",
    "\t\tprint(\"Total no. of Gaussians analysed: \" + str(total_number_of_hills))\n",
    "\n",
    "\t\t# Definition Gamma Factor, allows to switch between WT and regular MetaD\n",
    "\t\tif WellTempered < 1:\n",
    "\t\t\tGamma_Factor = 1\n",
    "\t\telse:\n",
    "\t\t\tgamma = HILLS[0, 6]\n",
    "\t\t\tGamma_Factor = (gamma - 1) / (gamma)\n",
    "\t\t\t\n",
    "\tFtot_den_limit = 1E-10\n",
    "\n",
    "\tfor i in range(total_number_of_hills):\n",
    "\t\t\n",
    "\t\t#Probability density limit, below which (fes or error) values aren't considered.\n",
    "\t\t# Ftot_den_limit = (i+1)*stride * 10**-5\n",
    "\t\t\n",
    "\t\t# Build metadynamics potential\n",
    "\t\ts_x = HILLS[i, 1]  # centre x-position of Gaussian\n",
    "\t\ts_y = HILLS[i, 2]  # centre y-position of Gaussian\n",
    "\t\tsigma_meta2_x = HILLS[i, 3] ** 2  # width of Gaussian\n",
    "\t\tsigma_meta2_y = HILLS[i, 4] ** 2  # width of Gaussian\n",
    "\t\theight_meta = HILLS[i, 5] * Gamma_Factor  # Height of Gaussian\n",
    "\n",
    "\t\tperiodic_images = find_periodic_point(s_x, s_y, min_grid, max_grid, periodic)\n",
    "\t\tfor j in range(len(periodic_images)):\n",
    "\t\t\tkernelmeta = np.exp(-0.5 * (((X - periodic_images[j][0]) ** 2) / sigma_meta2_x + (\n",
    "\t\t\t\t\t\t(Y - periodic_images[j][1]) ** 2) / sigma_meta2_y))  # potential erorr in calc. of s-s_t\n",
    "\t\t\tFbias_x = Fbias_x + height_meta * kernelmeta * ((X - periodic_images[j][0]) / sigma_meta2_x);\n",
    "\t\t\tFbias_y = Fbias_y + height_meta * kernelmeta * ((Y - periodic_images[j][1]) / sigma_meta2_y);\n",
    "\n",
    "\t\t# Estimate the biased proabability density p_t ^ b(s)\n",
    "\t\tpb_t = np.zeros(nbins)\n",
    "\t\tFpbt_x = np.zeros(nbins)\n",
    "\t\tFpbt_y = np.zeros(nbins)\n",
    "\n",
    "\t\tdata_x = position_x[i * stride: (i + 1) * stride]\n",
    "\t\tdata_y = position_y[i * stride: (i + 1) * stride]\n",
    "  \n",
    "\t\tfor j in range(stride):\n",
    "\t\t\tperiodic_images = find_periodic_point(data_x[j], data_y[j], min_grid, max_grid, periodic)\n",
    "\t\t\tfor k in range(len(periodic_images)):\n",
    "\t\t\t\tkernel = const * np.exp(\n",
    "\t\t\t\t\t- (1 / (2 * bw2)) * ((X - periodic_images[k][0]) ** 2 + (Y - periodic_images[k][1]) ** 2))\n",
    "\t\t\t\tpb_t = pb_t + kernel;\n",
    "\t\t\t\tFpbt_x = Fpbt_x + kernel * kT * (X - periodic_images[k][0]) / bw2\n",
    "\t\t\t\tFpbt_y = Fpbt_y + kernel * kT * (Y - periodic_images[k][1]) / bw2\n",
    "\t\tpb_t = np.where(pb_t > Ftot_den_limit, pb_t, 0)  # truncated probability density of window\n",
    "\n",
    "\t\t# Calculate total probability density\n",
    "\t\tFtot_den = Ftot_den + pb_t\n",
    "\t\t\n",
    "\t\t# Calculate x-component of Force\n",
    "\t\tdfds_x = np.divide(Fpbt_x, pb_t, out=np.zeros_like(Fpbt_x), where=pb_t > 0) + Fbias_x - F_static_x\n",
    "\t\tFtot_num_x = Ftot_num_x + pb_t * dfds_x\n",
    "\t\tFtot_x = np.divide(Ftot_num_x, Ftot_den, out=np.zeros_like(Fpbt_x), where=Ftot_den > 0)\n",
    "\t\t\n",
    "\t\t# Calculate y-component of Force\n",
    "\t\tdfds_y = np.divide(Fpbt_y, pb_t, out=np.zeros_like(Fpbt_y), where=pb_t > 0) + Fbias_y - F_static_y\n",
    "\t\tFtot_num_y = Ftot_num_y + pb_t * dfds_y\n",
    "\t\tFtot_y = np.divide(Ftot_num_y, Ftot_den, out=np.zeros_like(Fpbt_y), where=Ftot_den > 0)\n",
    "\n",
    "\t\t# calculate on the fly error components\n",
    "\t\tFtot_den2 = Ftot_den2 + pb_t ** 2\n",
    "\t\tofv_num_x += pb_t * dfds_x ** 2\n",
    "\t\tofv_num_y += pb_t * dfds_y ** 2\n",
    "\n",
    "\t\t# calculate ofe (standard error)\n",
    "\t\t[ofv, ofe] = mean_force_variance(Ftot_den, Ftot_den2, Ftot_x, Ftot_y, ofv_num_x, ofv_num_y, Ftot_den_limit=Ftot_den_limit)\n",
    "\t\t\n",
    "\t\tofe_history.append( sum(sum(ofe)) / (np.count_nonzero(ofe)))\n",
    "\t\ttime_history.append(HILLS[i,0])\n",
    "\t\t#print progress\n",
    "\t\tif (i + 1) % log_pace == 0:\n",
    "\t\t\tprint(\"|\" + str(i + 1) + \"/\" + str(total_number_of_hills) + \"|==> Average Mean Force Error: \" + str(ofe_history[-1]))\n",
    "\t\t\t\n",
    "\treturn [X, Y, Ftot_den, Ftot_den2, Ftot_x, Ftot_y, ofv_num_x, ofv_num_y, ofv, ofe, cutoff, volume_history, ofe_history, time_history]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of Gaussians analysed: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-94-27c832a61c41>:107: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ofe_history.append( sum(sum(ofe)) / (np.count_nonzero(ofe)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|200/200|==> Average Mean Force Error: 37.044953421952854\n",
      "time for >>MFI_normal<< is: 6.723116159439087\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "[X, Y, Ftot_den, Ftot_den2, Ftot_x, Ftot_y, ofv_num_x, ofv_num_y, ofv, ofe, cutoff, volume_history, ofe_history, time_history] = MFI_2D(HILLS=hills, position_x=pos_x, position_y=pos_y, bw=0.1, kT=kT,\n",
    "\t\t   min_grid=min_grid, max_grid=max_grid, nbins=nbins,\n",
    "\t\t   log_pace=n_eval, error_pace=n_eval/10, nhills=n_eval, periodic=1)\n",
    "\n",
    "\n",
    "t_normal = time.time()-start\t\n",
    "print(\"time for >>MFI_normal<< is:\", t_normal)\n",
    "\n",
    "[X, Y, FES] = FFT_intg_2D(Ftot_x, Ftot_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Numpy method (optimise the use of numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_force_variance_numpy(Ftot_den, Ftot_den2, Ftot_x, Ftot_y, ofv_num_x, ofv_num_y, Ftot_den_limit=0):\n",
    "\n",
    "\tFtot_den_sq = np.square(Ftot_den)\n",
    "\tFtot_den_diff = Ftot_den_sq-Ftot_den2\n",
    "\tbessel_corr = np.divide(Ftot_den_sq , Ftot_den_diff, out=np.zeros_like(Ftot_den), where=Ftot_den_diff > 0)\n",
    "\n",
    "\tofv_x = np.multiply(np.divide(ofv_num_x , Ftot_den, out=np.zeros_like(Ftot_den), where=Ftot_den > 0) - np.square(Ftot_x) , bessel_corr )\n",
    "\tofe_x = np.sqrt(ofv_x)\n",
    "\t\n",
    "\tofv_y = np.multiply(np.divide(ofv_num_y , Ftot_den, out=np.zeros_like(Ftot_den), where=Ftot_den > 0) - np.square(Ftot_y) , bessel_corr )\n",
    "\tofe_y = np.sqrt(ofv_y)\n",
    "\t\n",
    "\tofv = np.sqrt(np.square(ofv_x) + np.square(ofv_y))\n",
    "\tofe = np.sqrt(np.square(ofe_x) + np.square(ofe_y))\n",
    "\t\t\n",
    "\treturn [ofv, ofe]\n",
    "\n",
    "def MFI_2D_numpy(HILLS=\"HILLS\", position_x=\"position_x\", position_y=\"position_y\", bw=1, kT=1,\n",
    "\t\t   min_grid=np.array((-np.pi, -np.pi)), max_grid=np.array((np.pi, np.pi)), nbins=np.array((200, 200)),\n",
    "\t\t   log_pace=5, error_pace=10, WellTempered=1, nhills=-1, periodic=1):\n",
    "\n",
    "\tfor _init in range(1):\n",
    "\t\tgridx = np.linspace(min_grid[0], max_grid[0], nbins[0])\n",
    "\t\tgridy = np.linspace(min_grid[1], max_grid[1], nbins[1])\n",
    "\t\tgrid_space = np.array(((max_grid[0] - min_grid[0]) / (nbins[0]-1), (max_grid[1] - min_grid[1]) / (nbins[1]-1)))\n",
    "\t\tX, Y = np.meshgrid(gridx, gridy)\n",
    "\t\tstride = int(len(position_x) / len(HILLS))\n",
    "\t\tconst = (1 / (bw * np.sqrt(2 * np.pi) * stride))\n",
    "\n",
    "\t\t# Optional - analyse only nhills, if nhills is set\n",
    "\t\tif nhills > 0:\n",
    "\t\t\ttotal_number_of_hills = nhills\n",
    "\t\telse:\n",
    "\t\t\ttotal_number_of_hills = len(HILLS)\n",
    "\t\tbw2 = bw ** 2\n",
    "\n",
    "\t\t# Initialize force terms\n",
    "\t\tFbias_x = np.zeros(nbins)\n",
    "\t\tFbias_y = np.zeros(nbins)\n",
    "\t\tFtot_num_x = np.zeros(nbins)\n",
    "\t\tFtot_num_y = np.zeros(nbins)\n",
    "\t\tFtot_den = np.zeros(nbins)\n",
    "\t\tFtot_den2 = np.zeros(nbins)\n",
    "\t\tcutoff=np.zeros(nbins)\n",
    "\t\tofv_num_x = np.zeros(nbins)\n",
    "\t\tofv_num_y = np.zeros(nbins)\n",
    "\t\tvolume_history = []\n",
    "\t\tofe_history = []\n",
    "\t\ttime_history = []\n",
    "\n",
    "\t\t#Don't Calculate static force in this case\n",
    "\t\tF_static_x = np.zeros(nbins)\n",
    "\t\tF_static_y = np.zeros(nbins)\n",
    "\n",
    "\t\tprint(\"Total no. of Gaussians analysed: \" + str(total_number_of_hills))\n",
    "\n",
    "\t\t# Definition Gamma Factor, allows to switch between WT and regular MetaD\n",
    "\t\tif WellTempered < 1:\n",
    "\t\t\tGamma_Factor = 1\n",
    "\t\telse:\n",
    "\t\t\tgamma = HILLS[0, 6]\n",
    "\t\t\tGamma_Factor = (gamma - 1) / (gamma)\n",
    "\t\t\t\n",
    "\t\tFtot_den_limit = 1E-10\n",
    "\n",
    "\tfor i in range(total_number_of_hills):\n",
    "\t\t\t\t\n",
    "\t\t# Build metadynamics potential\n",
    "\t\ts_x = HILLS[i, 1]  # centre x-position of Gaussian\n",
    "\t\ts_y = HILLS[i, 2]  # centre y-position of Gaussian\n",
    "\t\tsigma_meta2_x = HILLS[i, 3] ** 2  # width of Gaussian\n",
    "\t\tsigma_meta2_y = HILLS[i, 4] ** 2  # width of Gaussian\n",
    "\t\theight_meta = HILLS[i, 5] * Gamma_Factor  # Height of Gaussian\n",
    "\n",
    "\t\tperiodic_images = find_periodic_point(s_x, s_y, min_grid, max_grid, periodic)\n",
    "\t\tfor j in range(len(periodic_images)):\n",
    "\n",
    "\t\t\tkernelmeta_x = np.exp( - np.square(gridx - periodic_images[j][0]) / (2 * sigma_meta2_x)) * height_meta\n",
    "\t\t\tkernelmeta_y = np.exp( - np.square(gridy - periodic_images[j][1]) / (2 * sigma_meta2_y))\n",
    "\t\t\t# kernelmeta = np.outer(kernelmeta_y, kernelmeta_x)\n",
    "      \n",
    "\t\t\tFbias_x = Fbias_x + np.outer(kernelmeta_y, np.multiply(kernelmeta_x, (gridx - periodic_images[j][0])) / sigma_meta2_x )\n",
    "\t\t\tFbias_y = Fbias_y + np.outer(np.multiply(kernelmeta_y, (gridy - periodic_images[j][1])) / sigma_meta2_y, kernelmeta_x )\n",
    "\n",
    "\t\t# Estimate the biased proabability density p_t ^ b(s)\n",
    "\t\tpb_t = np.zeros(nbins)\n",
    "\t\tFpbt_x = np.zeros(nbins)\n",
    "\t\tFpbt_y = np.zeros(nbins)\n",
    "\n",
    "\t\tdata_x = position_x[i * stride: (i + 1) * stride]\n",
    "\t\tdata_y = position_y[i * stride: (i + 1) * stride]\n",
    "  \n",
    "\t\tfor j in range(stride):\n",
    "\t\t\tperiodic_images = find_periodic_point(data_x[j], data_y[j], min_grid, max_grid, periodic)\n",
    "\t\t\tfor k in range(len(periodic_images)):\n",
    "\n",
    "\t\t\t\tkernel_x = np.exp( - np.square(gridx - periodic_images[k][0]) / (2 * bw2)) * const #add constant here for less computations\n",
    "\t\t\t\tkernel_y = np.exp( - np.square(gridy - periodic_images[k][1]) / (2 * bw2))\n",
    "\t\t\t\tkernel = np.outer(kernel_y, kernel_x)\n",
    "    \n",
    "\t\t\t\tkernel_x = kernel_x * kT / bw2 #add constant here for less computations\n",
    "    \n",
    "\t\t\t\tpb_t = pb_t + kernel\n",
    "    \n",
    "\t\t\t\tFpbt_x = Fpbt_x + np.outer(kernel_y, np.multiply(kernel_x, (gridx - periodic_images[k][0])) )\n",
    "\t\t\t\tFpbt_y = Fpbt_y + np.outer(np.multiply(kernel_y, (gridy - periodic_images[k][1])) , kernel_x )\n",
    "\n",
    "\t\tpb_t = np.where(pb_t > Ftot_den_limit, pb_t, 0)  # truncated probability density of window\n",
    "\n",
    "\t\t# Calculate total probability density\n",
    "\t\tFtot_den = Ftot_den + pb_t\n",
    "\t\t\n",
    "\t\t# Calculate x-component of Force\n",
    "\t\tdfds_x = np.divide(Fpbt_x, pb_t, out=np.zeros_like(Ftot_den), where=pb_t > 0) + Fbias_x - F_static_x\n",
    "\t\tFtot_num_x = Ftot_num_x + np.multiply(pb_t, dfds_x)\n",
    "\t\t\n",
    "\t\t# Calculate y-component of Force\n",
    "\t\tdfds_y = np.divide(Fpbt_y, pb_t, out=np.zeros_like(Ftot_den), where=pb_t > 0) + Fbias_y - F_static_y\n",
    "\t\tFtot_num_y = Ftot_num_y + np.multiply(pb_t, dfds_y)\n",
    "\n",
    "\t\t# calculate on the fly error components\n",
    "\t\tFtot_den2 += np.square(pb_t)\n",
    "\t\tofv_num_x += np.multiply(pb_t, np.square(dfds_x))\n",
    "\t\tofv_num_y += np.multiply(pb_t, np.square(dfds_y))\n",
    "\n",
    "\t\t#force and calculate error\n",
    "\t\tif (i + 1) % error_pace == 0 or (i+1) == total_number_of_hills:\n",
    "\t\t\t\n",
    "\t\t\tFtot_x = np.divide(Ftot_num_x, Ftot_den, out=np.zeros_like(Ftot_den), where=Ftot_den > 0)\n",
    "\t\t\tFtot_y = np.divide(Ftot_num_y, Ftot_den, out=np.zeros_like(Ftot_den), where=Ftot_den > 0)\n",
    "\n",
    "\t\t\t[ofv, ofe] = mean_force_variance_numpy(Ftot_den, Ftot_den2, Ftot_x, Ftot_y, ofv_num_x, ofv_num_y)\n",
    "\t\t\n",
    "\t\t\tofe_history.append( np.sum(ofe) / (np.count_nonzero(ofe)))\n",
    "\t\t\ttime_history.append(HILLS[i,0])\n",
    "\t\t\n",
    "  \t\t#print progress\n",
    "\t\tif (i + 1) % log_pace == 0:\n",
    "\t\t\tprint(\"|\" + str(i + 1) + \"/\" + str(total_number_of_hills) + \"|==> Average Mean Force Error: \" + str(ofe_history[-1]))\n",
    "\t\t\t\n",
    "\treturn [X, Y, Ftot_den, Ftot_den2, Ftot_x, Ftot_y, ofv_num_x, ofv_num_y, ofv, ofe, cutoff, volume_history, ofe_history, time_history]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of Gaussians analysed: 200\n",
      "|200/200|==> Average Mean Force Error: 37.04495342195384\n",
      "\n",
      "time for >>MFI_numpy<< is: 1.766749620437622\n",
      "time saving: 73.72 %\n",
      "\n",
      "ERROR:\n",
      "differecen in Ftot_den: 9.36287822348276e-17\n",
      "differecen in Ftot_den2: 4.2760839957035474e-17\n",
      "differecen in Ftot_x: 2.654507001579112e-15\n",
      "differecen in Ftot_y: 2.2315611815024172e-15\n",
      "differecen in ofv_num_x: 9.65193627643362e-14\n",
      "differecen in ofv_num_y: 8.353243712830433e-14\n",
      "\n",
      "differecen in FES: 7.261746759468224e-15\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "[X, Y, Ftot_dens, Ftot_den2s, Ftot_xs, Ftot_ys, ofv_num_xs, ofv_num_ys, ofv, ofe, cutoff, volume_history, ofe_history, time_history] = MFI_2D_numpy(HILLS=HILLS, position_x=p_x, position_y=p_y, bw=0.1, kT=kT,\n",
    "\t\t   min_grid=min_grid, max_grid=max_grid, nbins=nbins,\n",
    "\t\t   log_pace=n_eval, error_pace=n_eval/10, nhills=n_eval, periodic=1)\n",
    "\n",
    "\n",
    "t_numpy = time.time()-start\n",
    "print(\"\\ntime for >>MFI_numpy<< is:\", t_numpy)\n",
    "print(\"time saving:\", round(100*(t_normal - t_numpy)/t_normal, 2), \"%\")\n",
    "\n",
    "[X, Y, FESs] = FFT_intg_2D(Ftot_xs, Ftot_ys)\n",
    "\t\n",
    "print(\"\\nERROR:\")\n",
    "print(\"differecen in Ftot_den:\", sum(sum(abs(Ftot_den - Ftot_dens))) / 200**2)\n",
    "print(\"differecen in Ftot_den2:\", sum(sum(abs(Ftot_den2 - Ftot_den2s))) / 200**2)\n",
    "print(\"differecen in Ftot_x:\", sum(sum(abs(Ftot_x - Ftot_xs))) / 200**2)\n",
    "print(\"differecen in Ftot_y:\", sum(sum(abs(Ftot_y - Ftot_ys))) / 200**2)\n",
    "print(\"differecen in ofv_num_x:\", sum(sum(abs(ofv_num_x - ofv_num_xs))) / 200**2)\n",
    "print(\"differecen in ofv_num_y:\", sum(sum(abs(ofv_num_y - ofv_num_ys))) / 200**2)\n",
    "print(\"\\ndifferecen in FES:\", sum(sum(abs(FES-FESs))) / 200**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Numba method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) No-Loop method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(1)\n",
    "# plt.contourf(X,Y,FESs)\n",
    "# plt.colorbar()\n",
    "# plt.scatter(HILLS[:n_eval,1], HILLS[:n_eval,2], c=\"r\", s=2)\n",
    "\n",
    "# plt.figure(4)\n",
    "# plt.contourf(X,Y,FES)\n",
    "# plt.colorbar()\n",
    "# plt.scatter(HILLS[:n_eval,1], HILLS[:n_eval,2], c=\"r\", s=2)\n",
    "\n",
    "\n",
    "# # plt.figure(2)\n",
    "# # plt.contourf(X,Y,Ftot_xs, levels = np.linspace(-160, 160, 21))\n",
    "# # plt.colorbar()\n",
    "# # plt.scatter(HILLS[:n_eval,1], HILLS[:n_eval,2], c=\"r\", s=2)\n",
    "\n",
    "# # plt.figure(5)\n",
    "# # plt.contourf(X,Y,Ftot_x, levels = np.linspace(-160, 160, 21))\n",
    "# # plt.colorbar()\n",
    "# # plt.scatter(HILLS[:n_eval,1], HILLS[:n_eval,2], c=\"r\", s=2)\n",
    "\n",
    "# plt.figure(6)\n",
    "# plt.contourf(X,Y,Ftot_x-Ftot_xs)\n",
    "# plt.colorbar()\n",
    "# plt.scatter(HILLS[:n_eval,1], HILLS[:n_eval,2], c=\"r\", s=2)\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "03ae04260e478434a99f6a85d47b9294450c44a76b572c3ffee886dfa13495b2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
